# ExoDec Project Summary

## 1. Project Overview
**ExoDec** is a Deep Learning-based project designed to detect exoplanets using data from the **Transiting Exoplanet Survey Satellite (TESS)**. The system analyzes light curves (brightness over time) of stars to identify potential transit signals caused by planets passing in front of them.

## 2. Theoretical Background
The project relies on the **Transit Photometry Method**.

*   **The Transit Method**: When a planet passes in front of its host star (from our perspective), it blocks a tiny fraction of the star's light, causing a periodic dip in brightness.
*   **Light Curves**: A graph of brightness vs. time. A planet candidate typically shows a U-shaped or V-shaped dip that repeats at a regular interval (the planet's orbital period).
*   **False Positives**: Not all dips are planets. They can be caused by:
    *   **Eclipsing Binaries (EBs)**: Two stars orbiting each other.
    *   **Instrumental Flux**: Noise from the telescope.
    *   **Stellar Variability**: Spots or flares on the star.

## 3. Implementation Details

### Data Pipeline
1.  **Input Data**: The system uses TESS Light Curves (`.fits` files) sourced via the `lightkurve` library.
2.  **Preprocessing ([preprocess_lcs.py](file:///home/anuj/mygit/ExoDec/preprocessing/preprocess_lcs.py))**:
    *   **Stitching**: Combines light curves from different sectors.
    *   **Folding**: The light curve is "folded" over the detected period so all transit events align on top of each other.
    *   **Multi-View Generation**: To help the model distinguish real planets from false positives (like EBs), multiple "views" of the folded light curve are generated:
        *   **Global View**: The entire orbital phase (binned to 201 points) to see the full context.
        *   **Local View**: A zoomed-in view of the transit event itself (binned to 81 points) to analyze the shape of the dip.
        *   **Odd/Even View (Secondary View)**: Folds the light curve to check for secondary eclipses (a signature of binary stars) by looking at phase 0.5.
    *   **TFRecords**: The processed views are saved as TensorFlow Records (`.tfRecords`) for highly efficient training.

### Model Architecture ([TfRecord_model.ipynb](file:///home/anuj/mygit/ExoDec/preprocessing/TfRecord_model.ipynb))
The model is a **Multi-Input Convolutional Neural Network (CNN)** built with TensorFlow/Keras.

*   **Inputs**: The model accepts 4 simultaneous inputs: `local`, `global`, [odd_even](file:///home/anuj/mygit/ExoDec/preprocessing/preprocess_lcs.py#344-350), and `shifted` views.
*   **Feature Extraction**: Each input passes through its own branch of **1D Convolutional Layers (`Conv1D`)** followed by **Max Pooling**.
*   **Fusion**: The features from all branches are **concatenated** into a single vector.
*   **Classification**: Fully connected (`Dense`) layers process the combined features, ending in a single output neuron (`sigmoid` activation) that predicts the probability of the target being a planet candidate ("PC").

## 4. Key Files & Structure
*   **`preprocessing/`**: Contains the core logic.
    *   [preprocess_lcs.py](file:///home/anuj/mygit/ExoDec/preprocessing/preprocess_lcs.py): Main script to load, process, and save light curves.
    *   [TfRecord_model.ipynb](file:///home/anuj/mygit/ExoDec/preprocessing/TfRecord_model.ipynb): The training notebook containing the CNN architecture.
    *   `datasets/`: Holds catalog CSVs (`tic-catalog`, `toi-catalog`).
    *   [lightcurves/](file:///home/anuj/mygit/ExoDec/preprocessing/preprocess_lcs.py#192-203): Storage for downloaded `.fits` files.
*   **`Research_Papers/`**: References for Transit and Radial Velocity methods.

## 5. Current State
*   The **logic** for data processing and model training is complete and located in the `preprocessing` folder.
*   **[exodecNB.ipynb](file:///home/anuj/mygit/ExoDec/exodecNB.ipynb)** in the root directory is currently empty/new and likely intended to be the main entry point or demo notebook.
